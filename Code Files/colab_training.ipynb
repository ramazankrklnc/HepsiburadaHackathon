{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oU0Ifes6Lz94"
      },
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phanelerin kurulumu\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om7gegCqL-Ve",
        "outputId": "166d17cd-c836-45b7-82c0-e051538d6319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive baÄŸlantÄ±sÄ±\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub7KAOlaLz95",
        "outputId": "1866d337-31dd-4709-f990-3169846768a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os, gc, math, time, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------- CONFIG -------------------\n",
        "CFG = {\n",
        "    # Genel\n",
        "    'SEED': 42,\n",
        "    'DEBUG': False,\n",
        "\n",
        "    # Veri YollarÄ± (Colab)\n",
        "    'DATA_DIR': '/content/drive/MyDrive/data',           # CSV dosyalarÄ±\n",
        "    'EMBEDDINGS_DIR': '/content/drive/MyDrive/embeddings', # Embedding dosyalarÄ±\n",
        "\n",
        "    # Model BoyutlarÄ±\n",
        "    'H1': 2048,\n",
        "    'H2': 1024,\n",
        "    'DROPOUT1': 0.2,\n",
        "    'DROPOUT2': 0.1,\n",
        "\n",
        "    # Training\n",
        "    'VAL_SIZE': 0.1,\n",
        "    'BATCH_TRAIN': 64,     # ArtÄ±rÄ±lmÄ±ÅŸ batch size\n",
        "    'BATCH_PRED': 128,\n",
        "    'EPOCHS': 20,          # Daha uzun eÄŸitim\n",
        "    'LR': 5e-4,           # BaÅŸlangÄ±Ã§ learning rate\n",
        "    'MIN_LR': 1e-6,       # Minimum learning rate\n",
        "    'WARMUP_EPOCHS': 2,    # Warmup dÃ¶nemi\n",
        "    'WD': 0.01,\n",
        "    'LABEL_SMOOTH': 0.15,  # ArtÄ±rÄ±lmÄ±ÅŸ label smoothing\n",
        "    'PATIENCE': 5,         # Daha uzun patience\n",
        "    'CLIP_NORM': 1.0,\n",
        "    'FINETUNE_STEPS': 3    # Daha fazla fine-tuning\n",
        "}\n",
        "\n",
        "# Seed\n",
        "np.random.seed(CFG['SEED'])\n",
        "torch.manual_seed(CFG['SEED'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(CFG['SEED'])\n",
        "\n",
        "# Device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', device)\n",
        "if device == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6ZskGTpLz96",
        "outputId": "ef861a8b-da02-4698-f994-1caaa016f135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings...\n",
            "Train shape: (848237, 2)\n",
            "Test shape: (217241, 2)\n",
            "Embedding shapes: (848237, 1024) (217241, 1024)\n"
          ]
        }
      ],
      "source": [
        "# ------------------- LOAD DATA & EMBEDDINGS -------------------\n",
        "# CSV dosyalarÄ±\n",
        "train = pd.read_csv(f\"{CFG['DATA_DIR']}/train.csv\")\n",
        "test = pd.read_csv(f\"{CFG['DATA_DIR']}/test.csv\")\n",
        "sample = pd.read_csv(f\"{CFG['DATA_DIR']}/sample_submission.csv\")\n",
        "\n",
        "if CFG['DEBUG']:\n",
        "    print('DEBUG MODE: Az veri kullanÄ±lÄ±yor!')\n",
        "    train = train.sample(1000, random_state=CFG['SEED']).reset_index(drop=True)\n",
        "    test = test.sample(1000, random_state=CFG['SEED']).reset_index(drop=True)\n",
        "\n",
        "# Label encoding\n",
        "le = LabelEncoder()\n",
        "y_all = le.fit_transform(train['label'].astype(str).values)\n",
        "\n",
        "# Embeddings\n",
        "print('Loading embeddings...')\n",
        "X_train_embed = np.load(f\"{CFG['EMBEDDINGS_DIR']}/X_train_multilingual_e5_large.npy\", mmap_mode='r')\n",
        "X_test_embed = np.load(f\"{CFG['EMBEDDINGS_DIR']}/X_test_multilingual_e5_large.npy\", mmap_mode='r')\n",
        "\n",
        "print('Train shape:', train.shape)\n",
        "print('Test shape:', test.shape)\n",
        "print('Embedding shapes:', X_train_embed.shape, X_test_embed.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QSDsmFK4Lz96"
      },
      "outputs": [],
      "source": [
        "# ------------------- MODEL CLASSES -------------------\n",
        "class CosineHead(torch.nn.Module):\n",
        "    def __init__(self, in_dim, num_classes, s=30.0):\n",
        "        super().__init__()\n",
        "        self.W = torch.nn.Parameter(torch.randn(in_dim, num_classes))\n",
        "        self.s = s\n",
        "        torch.nn.init.xavier_normal_(self.W)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.normalize(x, dim=1)\n",
        "        W = torch.nn.functional.normalize(self.W, dim=0)\n",
        "        return self.s * (x @ W)\n",
        "\n",
        "class ImprovedMLP(torch.nn.Module):\n",
        "    def __init__(self, in_dim, num_classes, h1=2048, h2=1024, h3=512, d1=0.3, d2=0.2, d3=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # First block\n",
        "        self.block1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_dim, h1),\n",
        "            torch.nn.BatchNorm1d(h1),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(d1)\n",
        "        )\n",
        "\n",
        "        # Second block with residual\n",
        "        self.block2 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(h1, h2),\n",
        "            torch.nn.BatchNorm1d(h2),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(d2)\n",
        "        )\n",
        "        self.residual2 = torch.nn.Linear(h1, h2) if h1 != h2 else torch.nn.Identity()\n",
        "\n",
        "        # Third block with residual\n",
        "        self.block3 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(h2, h3),\n",
        "            torch.nn.BatchNorm1d(h3),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(d3)\n",
        "        )\n",
        "        self.residual3 = torch.nn.Linear(h2, h3) if h2 != h3 else torch.nn.Identity()\n",
        "\n",
        "        self.head = CosineHead(h3, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass with residual connections\n",
        "        x1 = self.block1(x)\n",
        "        x2 = self.block2(x1) + self.residual2(x1)\n",
        "        x3 = self.block3(x2) + self.residual3(x2)\n",
        "        return self.head(x3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Cf5oozZ0Lz96"
      },
      "outputs": [],
      "source": [
        "# ------------------- TRAINING FUNCTIONS -------------------\n",
        "def iterate_idx(idxs, batch=1024, shuffle=True, seed=CFG['SEED']):\n",
        "    idx = np.array(idxs)\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(idx)\n",
        "    for i in range(0, len(idx), batch):\n",
        "        j = idx[i:i+batch]\n",
        "        xb = torch.as_tensor(X_train_embed[j], dtype=torch.float32, device=device)\n",
        "        yb = torch.as_tensor(y_all[j], dtype=torch.long, device=device)\n",
        "        yield xb, yb\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_f1(idxs, batch=2048):\n",
        "    model_clf.eval()\n",
        "    preds = []\n",
        "    for i in range(0, len(idxs), batch):\n",
        "        j = idxs[i:i+batch]\n",
        "        xb = torch.as_tensor(X_train_embed[j], dtype=torch.float32, device=device)\n",
        "        logits = model_clf(xb)\n",
        "        preds.append(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "    return f1_score(y_all[idxs], np.concatenate(preds), average='macro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXLkU1PULz96",
        "outputId": "46430fdd-bd2b-40cc-c20d-13b74327e27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ImprovedMLP...\n",
            "[01/20] Val F1: 0.0005 | 145.5s\n",
            "[02/20] Val F1: 0.4102 | 142.6s\n",
            "[03/20] Val F1: 0.4435 | 141.8s\n",
            "[04/20] Val F1: 0.5020 | 141.3s\n",
            "[05/20] Val F1: 0.5299 | 141.6s\n",
            "[06/20] Val F1: 0.5525 | 141.6s\n",
            "[07/20] Val F1: 0.5715 | 141.4s\n",
            "[08/20] Val F1: 0.5879 | 141.5s\n",
            "[09/20] Val F1: 0.5985 | 141.4s\n",
            "[10/20] Val F1: 0.6099 | 141.4s\n",
            "[11/20] Val F1: 0.6196 | 141.7s\n",
            "[12/20] Val F1: 0.6312 | 142.1s\n",
            "[13/20] Val F1: 0.6386 | 142.0s\n",
            "[14/20] Val F1: 0.6474 | 142.0s\n",
            "[15/20] Val F1: 0.6550 | 141.7s\n",
            "[16/20] Val F1: 0.6594 | 141.9s\n",
            "[17/20] Val F1: 0.6650 | 141.9s\n",
            "[18/20] Val F1: 0.6681 | 140.9s\n",
            "[19/20] Val F1: 0.6705 | 141.3s\n",
            "[20/20] Val F1: 0.6709 | 141.5s\n",
            "Best Val F1: 0.6709\n"
          ]
        }
      ],
      "source": [
        "# ------------------- TRAINING -------------------\n",
        "# Train-Val split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    np.arange(X_train_embed.shape[0]),\n",
        "    y_all,\n",
        "    test_size=CFG['VAL_SIZE'],\n",
        "    random_state=CFG['SEED'],\n",
        "    stratify=y_all\n",
        ")\n",
        "\n",
        "# Model init\n",
        "in_dim = X_train_embed.shape[1]\n",
        "num_classes = len(le.classes_)\n",
        "model_clf = ImprovedMLP(\n",
        "    in_dim=in_dim,\n",
        "    num_classes=num_classes,\n",
        "    h1=CFG['H1'],\n",
        "    h2=CFG['H2'],\n",
        "    h3=512,  # ÃœÃ§Ã¼ncÃ¼ katman boyutu\n",
        "    d1=CFG['DROPOUT1'],\n",
        "    d2=CFG['DROPOUT2'],\n",
        "    d3=0.1  # ÃœÃ§Ã¼ncÃ¼ katman dropout\n",
        ").to(device)\n",
        "\n",
        "# Class weights\n",
        "cls_w_np = compute_class_weight('balanced', classes=np.arange(num_classes), y=y_all)\n",
        "cls_w = torch.tensor(cls_w_np, dtype=torch.float32, device=device)\n",
        "\n",
        "# Optimizer\n",
        "opt = torch.optim.AdamW(model_clf.parameters(), lr=CFG['LR'], weight_decay=CFG['WD'])\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "\n",
        "# Cosine annealing with warmup scheduler\n",
        "def get_lr_multiplier(epoch, warmup_epochs, total_epochs):\n",
        "    if epoch < warmup_epochs:\n",
        "        return epoch / warmup_epochs\n",
        "    else:\n",
        "        progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
        "        return 0.5 * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "# Training loop with improved scheduling and monitoring\n",
        "best_f1, best_state, bad_epochs = -1.0, None, 0\n",
        "print('Training ImprovedMLP...')\n",
        "\n",
        "# Training statistics\n",
        "train_losses = []\n",
        "val_f1_scores = []\n",
        "\n",
        "for ep in range(1, CFG['EPOCHS']+1):\n",
        "    model_clf.train()\n",
        "    t0 = time.time()\n",
        "    epoch_losses = []\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    lr_mult = get_lr_multiplier(ep-1, CFG['WARMUP_EPOCHS'], CFG['EPOCHS'])\n",
        "    current_lr = CFG['LR'] * lr_mult\n",
        "    current_lr = max(current_lr, CFG['MIN_LR'])\n",
        "    for param_group in opt.param_groups:\n",
        "        param_group['lr'] = current_lr\n",
        "\n",
        "    it_train = iterate_idx(X_tr, batch=CFG['BATCH_TRAIN'], shuffle=True, seed=CFG['SEED']+ep)\n",
        "    for xb, yb in it_train:\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            # Mixup ile eÄŸitim\n",
        "            if np.random.random() < 0.5:  # %50 olasÄ±lÄ±kla mixup uygula\n",
        "                lam = np.random.beta(0.2, 0.2)\n",
        "                index = torch.randperm(xb.size(0)).to(xb.device)\n",
        "                mixed_x = lam * xb + (1 - lam) * xb[index]\n",
        "                logits = model_clf(mixed_x)\n",
        "                loss = lam * torch.nn.functional.cross_entropy(logits, yb, label_smoothing=CFG['LABEL_SMOOTH'], weight=cls_w) + \\\n",
        "                       (1 - lam) * torch.nn.functional.cross_entropy(logits, yb[index], label_smoothing=CFG['LABEL_SMOOTH'], weight=cls_w)\n",
        "            else:\n",
        "                # Normal eÄŸitim\n",
        "                logits = model_clf(xb)\n",
        "                loss = torch.nn.functional.cross_entropy(logits, yb, label_smoothing=CFG['LABEL_SMOOTH'], weight=cls_w)\n",
        "\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if CFG['CLIP_NORM'] is not None:\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model_clf.parameters(), CFG['CLIP_NORM'])\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "    val_f1 = eval_f1(X_val, batch=CFG['BATCH_PRED'])\n",
        "    dt = time.time() - t0\n",
        "    print(f'[{ep:02d}/{CFG[\"EPOCHS\"]}] Val F1: {val_f1:.4f} | {dt:.1f}s')\n",
        "\n",
        "    if val_f1 > best_f1 + 1e-4:\n",
        "        best_f1 = val_f1\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model_clf.state_dict().items()}\n",
        "        bad_epochs = 0\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= CFG['PATIENCE']:\n",
        "            print(f'Early stopping at epoch {ep} (no improvement in {CFG[\"PATIENCE\"]} epochs).')\n",
        "            break\n",
        "\n",
        "# En iyi modeli geri yÃ¼kle\n",
        "if best_state is not None:\n",
        "    model_clf.load_state_dict(best_state)\n",
        "print(f'Best Val F1: {best_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT4D6_FSLz97",
        "outputId": "50daa96f-b225-4307-c5f3-70eaf4dcc570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short finetune on full train...\n",
            "Predicting test...\n",
            "Submission dosyasÄ± kaydedildi: /content/drive/MyDrive/embeddings/submission.csv\n",
            "Bitti! ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "# ------------------- FINAL FINETUNE & PREDICT -------------------\n",
        "print('Short finetune on full train...')\n",
        "all_idx = np.arange(X_train_embed.shape[0])\n",
        "for step in range(CFG['FINETUNE_STEPS']):\n",
        "    model_clf.train()\n",
        "    for xb, yb in iterate_idx(all_idx, batch=CFG['BATCH_TRAIN'], shuffle=True, seed=CFG['SEED']+100+step):\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            logits = model_clf(xb)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, yb, label_smoothing=CFG['LABEL_SMOOTH'], weight=cls_w)\n",
        "        scaler.scale(loss).backward()\n",
        "        if CFG['CLIP_NORM'] is not None:\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model_clf.parameters(), CFG['CLIP_NORM'])\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "print('Predicting test...')\n",
        "preds = []\n",
        "model_clf.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(0, X_test_embed.shape[0], CFG['BATCH_PRED']):\n",
        "        xb = torch.as_tensor(X_test_embed[i:i+CFG['BATCH_PRED']], dtype=torch.float32, device=device)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            logits = model_clf(xb)\n",
        "        preds.append(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "y_test_pred = np.concatenate(preds)\n",
        "labels_pred = le.inverse_transform(y_test_pred)\n",
        "\n",
        "# Submission dosyasÄ± oluÅŸtur\n",
        "sub = sample.copy()\n",
        "sub['label'] = labels_pred\n",
        "sub_path = os.path.join(CFG['EMBEDDINGS_DIR'], 'submission.csv')\n",
        "sub.to_csv(sub_path, index=False)\n",
        "print(f'Submission dosyasÄ± kaydedildi: {sub_path}')\n",
        "print('Bitti! ðŸŽ‰')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_BaGoJqUdJG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
